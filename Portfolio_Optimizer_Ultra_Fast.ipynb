{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb28e2aa",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde02935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages (run once)\n",
    "!pip install --upgrade pandas yfinance tensorflow tensorflow-probability tqdm numpy xlsxwriter -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec539bcb",
   "metadata": {},
   "source": [
    "## üí° Alternative: If yfinance fails completely\n",
    "\n",
    "If you're experiencing persistent yfinance errors, you can:\n",
    "1. Use Google Sheets data (like your original code)\n",
    "2. Download from SET website and upload CSV\n",
    "3. Use alternative APIs (Alpha Vantage, Tiingo, etc.)\n",
    "\n",
    "Uncomment the cell below to use Google Sheets data instead:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bf1a90",
   "metadata": {},
   "source": [
    "## üìö Step 2: Import Libraries and Configure GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea82599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import itertools\n",
    "import time\n",
    "import yfinance as yf\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure GPU (Enable memory growth to avoid OOM errors)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"‚úÖ GPU Available: {len(gpus)} device(s)\")\n",
    "        for i, gpu in enumerate(gpus):\n",
    "            print(f\"   GPU {i}: {gpu.name}\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"‚ö†Ô∏è GPU Configuration Error: {e}\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è No GPU found. Using CPU (will be slower)\")\n",
    "\n",
    "print(f\"\\nüîß TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"üîß Numpy Version: {np.__version__}\")\n",
    "print(f\"üîß Pandas Version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daadc4f2",
   "metadata": {},
   "source": [
    "## üéØ Step 3: Ultra-Fast Vectorized Portfolio Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbad0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(reduce_retracing=True)\n",
    "def calculate_portfolio_metrics_vectorized(P0: tf.Tensor, Wi: tf.Tensor, fund: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor, tf.Tensor]:\n",
    "    \"\"\"\n",
    "    Ultra-optimized vectorized calculation using TensorFlow.\n",
    "    10-50x faster than traditional numpy/pandas loops.\n",
    "    \n",
    "    Args:\n",
    "        P0: Stock prices over time [time_steps, n_stocks]\n",
    "        Wi: Portfolio weights [n_samples, n_stocks]\n",
    "        fund: Investment fund amount (scalar)\n",
    "    \n",
    "    Returns:\n",
    "        avg_return: Average portfolio return [n_samples]\n",
    "        volatility: Portfolio volatility using log returns [n_samples]\n",
    "        variance: Portfolio variance [n_samples]\n",
    "    \"\"\"\n",
    "    # Calculate number of shares for each portfolio\n",
    "    # X0 = Wi * fund / P0[0]  -> [n_samples, n_stocks]\n",
    "    X0 = Wi * fund / P0[0]\n",
    "    \n",
    "    # Calculate portfolio value over time\n",
    "    # Port_Value = X0 @ P0.T  -> [n_samples, time_steps]\n",
    "    Port_Value = tf.matmul(tf.cast(X0, dtype=tf.float64), tf.transpose(P0))\n",
    "    \n",
    "    # Portfolio return (percentage)\n",
    "    Port_return = (Port_Value - fund) / fund * 100.0\n",
    "    \n",
    "    # Average return across time periods\n",
    "    avg_return = tf.reduce_mean(Port_return, axis=1)\n",
    "    \n",
    "    # Variance calculation\n",
    "    variance = tf.math.reduce_variance(Port_return, axis=1)\n",
    "    \n",
    "    # Log returns calculation (vectorized, no pandas shift needed)\n",
    "    epsilon = 1e-10  # Avoid log(0)\n",
    "    log_Port_Value = tf.math.log(Port_Value + epsilon)\n",
    "    \n",
    "    # Calculate log return differences (daily log returns)\n",
    "    log_return = log_Port_Value - tf.roll(log_Port_Value, shift=1, axis=1)\n",
    "    \n",
    "    # Calculate difference of log returns (second-order difference)\n",
    "    df_log = log_return - tf.roll(log_return, shift=2, axis=1)\n",
    "    \n",
    "    # Skip first 2 time steps (affected by roll operation)\n",
    "    df_log_valid = df_log[:, 2:]\n",
    "    \n",
    "    # Sum of squared log differences\n",
    "    sum_log = tf.reduce_sum(tf.square(df_log_valid), axis=1)\n",
    "    \n",
    "    # Volatility (realized volatility)\n",
    "    volatility = tf.sqrt(sum_log + epsilon)\n",
    "    \n",
    "    return avg_return, volatility, variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f9c772",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Step 4: Portfolio Optimizer Class (Supports N=2, N=3, N=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b5dbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UltraFastPortfolioOptimizer:\n",
    "    \"\"\"\n",
    "    Ultra-fast portfolio optimizer with batch processing and GPU acceleration.\n",
    "    Supports multiple portfolio sizes (N=2, N=3, N=5) and multiple return targets.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 df: pd.DataFrame, \n",
    "                 companies: np.ndarray, \n",
    "                 Wi: tf.Tensor, \n",
    "                 fund: float, \n",
    "                 n_stocks: int,\n",
    "                 batch_size: int = 100):\n",
    "        \"\"\"\n",
    "        Initialize optimizer.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame with stock prices (from yfinance)\n",
    "            companies: Array of stock combinations\n",
    "            Wi: Weight samples tensor [n_samples, n_stocks]\n",
    "            fund: Investment fund amount\n",
    "            n_stocks: Number of stocks per portfolio (2, 3, or 5)\n",
    "            batch_size: Batch size for processing (adjust based on memory)\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.companies = companies\n",
    "        self.Wi_tensor = tf.constant(Wi.numpy() if hasattr(Wi, 'numpy') else Wi, dtype=tf.float64)\n",
    "        self.fund_tensor = tf.constant(fund, dtype=tf.float64)\n",
    "        self.fund = float(fund)\n",
    "        self.n_stocks = n_stocks\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"üöÄ Ultra-Fast Portfolio Optimizer Initialized\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"üìä Portfolio Size (N): {n_stocks}\")\n",
    "        print(f\"üé≤ Weight Samples: {len(self.Wi_tensor):,}\")\n",
    "        print(f\"üè¢ Stock Combinations: {len(companies):,}\")\n",
    "        print(f\"üí∞ Investment Fund: {fund:,.0f} THB\")\n",
    "        print(f\"üì¶ Batch Size: {batch_size}\")\n",
    "        print(f\"üíª Device: {'GPU' if gpus else 'CPU'}\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    def process_batch(self, company_batch_indices: List[int]) -> List[Dict]:\n",
    "        \"\"\"Process a batch of company combinations.\"\"\"\n",
    "        batch_results = []\n",
    "        \n",
    "        for idx in company_batch_indices:\n",
    "            company_tuple = self.companies[idx]\n",
    "            \n",
    "            try:\n",
    "                # Get price data for this combination\n",
    "                if 'Close' in self.df.columns.names:\n",
    "                    A = self.df['Close'][list(company_tuple)].values\n",
    "                else:\n",
    "                    A = self.df[list(company_tuple)].values\n",
    "                \n",
    "                # Check for invalid data\n",
    "                if np.any(np.isnan(A)) or A.shape[0] == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Convert to tensor\n",
    "                P0 = tf.constant(A, dtype=tf.float64)\n",
    "                P0 = tf.reshape(P0, [-1, self.n_stocks])\n",
    "                \n",
    "                # Calculate metrics using vectorized function\n",
    "                avg_return, volatility, variance = calculate_portfolio_metrics_vectorized(\n",
    "                    P0, self.Wi_tensor, self.fund_tensor\n",
    "                )\n",
    "                \n",
    "                batch_results.append({\n",
    "                    'idx': idx,\n",
    "                    'companies': company_tuple,\n",
    "                    'avg_return': avg_return.numpy(),\n",
    "                    'volatility': volatility.numpy(),\n",
    "                    'variance': variance.numpy()\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                # Skip invalid combinations\n",
    "                continue\n",
    "        \n",
    "        return batch_results\n",
    "    \n",
    "    def optimize_multiple_returns(self, \n",
    "                                   return_targets: List[Tuple[float, float]], \n",
    "                                   max_combinations: Optional[int] = None) -> Tuple[Dict, Dict]:\n",
    "        \"\"\"\n",
    "        Optimize for multiple return targets simultaneously.\n",
    "        \n",
    "        Args:\n",
    "            return_targets: List of (min, max) return target tuples\n",
    "                           e.g., [(0.9999, 1.0001), (1.9999, 2.0001), ...]\n",
    "            max_combinations: Limit processing (for testing)\n",
    "        \n",
    "        Returns:\n",
    "            best_portfolios: Dictionary with best portfolio for each target\n",
    "            all_results: All valid results for each target\n",
    "        \"\"\"\n",
    "        n_combinations = len(self.companies) if max_combinations is None else min(max_combinations, len(self.companies))\n",
    "        \n",
    "        # Initialize storage\n",
    "        best_portfolios = {\n",
    "            i: {\n",
    "                'volatility': None,\n",
    "                'variance': None,\n",
    "                'weights': None,\n",
    "                'companies': None,\n",
    "                'avg_return': None,\n",
    "                'target_return': (return_targets[i][0] + return_targets[i][1]) / 2\n",
    "            }\n",
    "            for i in range(len(return_targets))\n",
    "        }\n",
    "        \n",
    "        all_results = {i: [] for i in range(len(return_targets))}\n",
    "        \n",
    "        # Calculate batch parameters\n",
    "        n_batches = (n_combinations + self.batch_size - 1) // self.batch_size\n",
    "        \n",
    "        print(f\"\\nüîÑ Starting Optimization...\")\n",
    "        print(f\"üìä Total Combinations: {n_combinations:,}\")\n",
    "        print(f\"üì¶ Number of Batches: {n_batches:,}\")\n",
    "        print(f\"üéØ Return Targets: {len(return_targets)}\")\n",
    "        print(f\"üî¢ Total Calculations: {n_combinations * len(self.Wi_tensor):,}\")\n",
    "        print(f\"\\n{'='*80}\\n\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Process batches with progress bar\n",
    "        with tqdm(total=n_batches, desc=\"Processing\", ncols=100) as pbar:\n",
    "            for batch_idx in range(n_batches):\n",
    "                batch_start = batch_idx * self.batch_size\n",
    "                batch_end = min(batch_start + self.batch_size, n_combinations)\n",
    "                \n",
    "                # Process batch\n",
    "                batch_indices = list(range(batch_start, batch_end))\n",
    "                batch_results = self.process_batch(batch_indices)\n",
    "                \n",
    "                # Update best portfolios for each return target\n",
    "                for result in batch_results:\n",
    "                    avg_returns = result['avg_return']\n",
    "                    volatilities = result['volatility']\n",
    "                    variances = result['variance']\n",
    "                    companies = result['companies']\n",
    "                    \n",
    "                    # Check each return target\n",
    "                    for target_idx, (min_ret, max_ret) in enumerate(return_targets):\n",
    "                        # Find portfolios meeting return constraint\n",
    "                        mask = (avg_returns >= min_ret) & (avg_returns <= max_ret)\n",
    "                        \n",
    "                        if np.any(mask):\n",
    "                            # Get best (minimum volatility)\n",
    "                            masked_vol = volatilities[mask]\n",
    "                            min_vol_idx = np.argmin(masked_vol)\n",
    "                            min_vol = masked_vol[min_vol_idx]\n",
    "                            \n",
    "                            # Get corresponding data\n",
    "                            masked_indices = np.where(mask)[0]\n",
    "                            global_idx = masked_indices[min_vol_idx]\n",
    "                            best_weights = self.Wi_tensor[global_idx].numpy()\n",
    "                            best_return = avg_returns[global_idx]\n",
    "                            best_variance = variances[global_idx]\n",
    "                            \n",
    "                            # Update if better than current best\n",
    "                            current_best = best_portfolios[target_idx]\n",
    "                            if current_best['volatility'] is None or min_vol < current_best['volatility']:\n",
    "                                best_portfolios[target_idx] = {\n",
    "                                    'volatility': float(min_vol),\n",
    "                                    'variance': float(best_variance),\n",
    "                                    'weights': best_weights,\n",
    "                                    'companies': companies,\n",
    "                                    'avg_return': float(best_return),\n",
    "                                    'target_return': (min_ret + max_ret) / 2\n",
    "                                }\n",
    "                                all_results[target_idx].append(best_portfolios[target_idx].copy())\n",
    "                \n",
    "                # Update progress\n",
    "                pbar.update(1)\n",
    "                \n",
    "                # Show intermediate results every 10% progress\n",
    "                if (batch_idx + 1) % max(1, n_batches // 10) == 0:\n",
    "                    elapsed = time.time() - start_time\n",
    "                    progress = batch_end / n_combinations * 100\n",
    "                    rate = batch_end / elapsed if elapsed > 0 else 0\n",
    "                    eta = (n_combinations - batch_end) / rate if rate > 0 else 0\n",
    "                    \n",
    "                    pbar.set_postfix({\n",
    "                        'Progress': f'{progress:.1f}%',\n",
    "                        'Rate': f'{rate:.1f} comb/s',\n",
    "                        'ETA': f'{eta/60:.1f}m'\n",
    "                    })\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        \n",
    "        # Print final statistics\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"‚úÖ Optimization Complete!\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"‚è±Ô∏è  Total Time: {total_time:.2f} seconds ({total_time/60:.2f} minutes)\")\n",
    "        print(f\"‚ö° Average Rate: {n_combinations/total_time:.1f} combinations/second\")\n",
    "        print(f\"üéØ Portfolios Found:\")\n",
    "        for i, portfolio in best_portfolios.items():\n",
    "            status = \"‚úÖ Found\" if portfolio['volatility'] is not None else \"‚ùå Not Found\"\n",
    "            print(f\"   {i+1}% Return: {status}\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        return best_portfolios, all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f4e356",
   "metadata": {},
   "source": [
    "## üé® Step 5: Results Display and Allocation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dda4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_allocation(weights: np.ndarray, \n",
    "                        fund: float, \n",
    "                        prices: Dict[str, float]) -> Tuple[Dict, float, float]:\n",
    "    \"\"\"\n",
    "    Calculate actual stock allocation and remaining cash.\n",
    "    \n",
    "    Args:\n",
    "        weights: Portfolio weights\n",
    "        fund: Investment fund\n",
    "        prices: Dictionary of stock prices\n",
    "    \n",
    "    Returns:\n",
    "        allocation: Dictionary with allocation details\n",
    "        total_invested: Total amount invested\n",
    "        remaining_cash: Remaining cash\n",
    "    \"\"\"\n",
    "    allocation = {}\n",
    "    total_invested = 0\n",
    "    \n",
    "    for stock, weight, price in zip(prices.keys(), weights, prices.values()):\n",
    "        amount_to_invest = fund * weight\n",
    "        shares = int(amount_to_invest / price)  # Buy whole shares only\n",
    "        invested = shares * price\n",
    "        \n",
    "        allocation[stock] = {\n",
    "            'weight': weight,\n",
    "            'shares': shares,\n",
    "            'price': price,\n",
    "            'invested': invested\n",
    "        }\n",
    "        total_invested += invested\n",
    "    \n",
    "    remaining_cash = fund - total_invested\n",
    "    \n",
    "    return allocation, total_invested, remaining_cash\n",
    "\n",
    "\n",
    "def display_results(best_portfolios: Dict, \n",
    "                   return_targets: List[Tuple[float, float]], \n",
    "                   df: pd.DataFrame, \n",
    "                   fund: float,\n",
    "                   n_stocks: int):\n",
    "    \"\"\"\n",
    "    Display optimization results in a beautiful format.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(f\"{'üèÜ PORTFOLIO OPTIMIZATION RESULTS':^90}\")\n",
    "    print(f\"{'Portfolio Size (N): ' + str(n_stocks):^90}\")\n",
    "    print(\"=\"*90 + \"\\n\")\n",
    "    \n",
    "    for target_idx, (min_ret, max_ret) in enumerate(return_targets):\n",
    "        portfolio = best_portfolios[target_idx]\n",
    "        target_return = (min_ret + max_ret) / 2\n",
    "        \n",
    "        print(f\"\\n{'‚îÄ'*90}\")\n",
    "        print(f\"üéØ TARGET RETURN: {target_return:.1f}%\")\n",
    "        print(f\"{'‚îÄ'*90}\")\n",
    "        \n",
    "        if portfolio['volatility'] is None:\n",
    "            print(\"\\n‚ùå No portfolio found for this return target\\n\")\n",
    "            continue\n",
    "        \n",
    "        companies = portfolio['companies']\n",
    "        weights = portfolio['weights']\n",
    "        \n",
    "        print(f\"\\nüìä Portfolio Metrics:\")\n",
    "        print(f\"   ‚Ä¢ Actual Return:    {portfolio['avg_return']:>10.4f}%\")\n",
    "        print(f\"   ‚Ä¢ Volatility:       {portfolio['volatility']:>10.6f}\")\n",
    "        print(f\"   ‚Ä¢ Variance:         {portfolio['variance']:>10.6f}\")\n",
    "        \n",
    "        print(f\"\\nüè¢ Selected Stocks & Allocation:\")\n",
    "        \n",
    "        # Get latest prices\n",
    "        latest_prices = {}\n",
    "        for stock in companies:\n",
    "            try:\n",
    "                if 'Close' in df.columns.names:\n",
    "                    latest_prices[stock] = df['Close'][stock].iloc[-1]\n",
    "                else:\n",
    "                    latest_prices[stock] = df[stock].iloc[-1]\n",
    "            except:\n",
    "                latest_prices[stock] = 0.0\n",
    "        \n",
    "        allocation, total_invested, remaining = calculate_allocation(\n",
    "            weights, fund, latest_prices\n",
    "        )\n",
    "        \n",
    "        # Display table header\n",
    "        print(f\"\\n   {'Stock':<15} {'Weight':>10} {'Shares':>10} {'Price':>12} {'Invested':>14}\")\n",
    "        print(f\"   {'-'*70}\")\n",
    "        \n",
    "        # Display each stock\n",
    "        for stock in companies:\n",
    "            info = allocation[stock]\n",
    "            print(f\"   {stock:<15} {info['weight']:>9.4f} {info['shares']:>10} \"\n",
    "                  f\"{info['price']:>12.2f} {info['invested']:>14,.2f}\")\n",
    "        \n",
    "        print(f\"\\nüí∞ Investment Summary:\")\n",
    "        print(f\"   ‚Ä¢ Total Fund:       {fund:>14,.2f} THB\")\n",
    "        print(f\"   ‚Ä¢ Total Invested:   {total_invested:>14,.2f} THB ({total_invested/fund*100:>5.1f}%)\")\n",
    "        print(f\"   ‚Ä¢ Remaining Cash:   {remaining:>14,.2f} THB ({remaining/fund*100:>5.1f}%)\")\n",
    "        print()\n",
    "\n",
    "\n",
    "def save_results_to_file(best_portfolios: Dict, \n",
    "                         return_targets: List[Tuple[float, float]], \n",
    "                         n_stocks: int,\n",
    "                         filename: str = \"optimization_results.txt\"):\n",
    "    \"\"\"\n",
    "    Save optimization results to a text file.\n",
    "    \"\"\"\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"=\"*90 + \"\\n\")\n",
    "        f.write(f\"PORTFOLIO OPTIMIZATION RESULTS (N={n_stocks})\\n\")\n",
    "        f.write(f\"Generated: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(\"=\"*90 + \"\\n\\n\")\n",
    "        \n",
    "        for target_idx, (min_ret, max_ret) in enumerate(return_targets):\n",
    "            portfolio = best_portfolios[target_idx]\n",
    "            target_return = (min_ret + max_ret) / 2\n",
    "            \n",
    "            f.write(f\"\\nTARGET RETURN: {target_return:.1f}%\\n\")\n",
    "            f.write(\"-\"*90 + \"\\n\")\n",
    "            \n",
    "            if portfolio['volatility'] is not None:\n",
    "                f.write(f\"Companies: {', '.join(portfolio['companies'])}\\n\")\n",
    "                f.write(f\"Weights: {portfolio['weights']}\\n\")\n",
    "                f.write(f\"Volatility: {portfolio['volatility']:.6f}\\n\")\n",
    "                f.write(f\"Variance: {portfolio['variance']:.6f}\\n\")\n",
    "                f.write(f\"Actual Return: {portfolio['avg_return']:.4f}%\\n\")\n",
    "            else:\n",
    "                f.write(\"No portfolio found\\n\")\n",
    "            f.write(\"\\n\")\n",
    "    \n",
    "    print(f\"\\nüíæ Results saved to: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f996d8b3",
   "metadata": {},
   "source": [
    "## üé¨ Step 6: Main Execution - Configure Your Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5493b34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION PARAMETERS - Adjust these for your analysis\n",
    "# ============================================================================\n",
    "\n",
    "# Portfolio configuration\n",
    "N_STOCKS = 2  # Change to 2, 3, or 5\n",
    "FUND = 500000  # Investment budget in THB\n",
    "NUM_WEIGHT_SAMPLES = 200000  # Number of random weight combinations to test\n",
    "\n",
    "# Data configuration\n",
    "START_DATE = '2022-10-19'\n",
    "END_DATE = '2022-11-30'\n",
    "\n",
    "# Processing configuration\n",
    "BATCH_SIZE = 100  # Adjust based on available memory (higher = faster but more RAM)\n",
    "MAX_COMBINATIONS = None  # Set to a number (e.g., 1000) for testing, None for all\n",
    "\n",
    "# Return targets (min, max) pairs\n",
    "RETURN_TARGETS = [\n",
    "    (0.9999, 1.0001),   # ~1% return\n",
    "    (1.9999, 2.0001),   # ~2% return\n",
    "    (2.9999, 3.0001),   # ~3% return\n",
    "    (3.9999, 4.0001),   # ~4% return\n",
    "    (4.9999, 5.0001),   # ~5% return\n",
    "]\n",
    "\n",
    "# Stock list (Thailand SET50)\n",
    "STOCK_LIST = [\n",
    "    \"ADVANC.BK\", \"AOT.BK\", \"BBL.BK\", \"BDMS.BK\", \"BEM.BK\", \"BGRIM.BK\",\n",
    "    \"BH.BK\", \"BJC.BK\", \"BTS.BK\", \"CBG.BK\", \"COM7.BK\", \"CPALL.BK\",\n",
    "    \"CPF.BK\", \"CPN.BK\", \"CRC.BK\", \"DELTA.BK\", \"DTAC.BK\", \"EA.BK\",\n",
    "    \"EGCO.BK\", \"GLOBAL.BK\", \"GPSC.BK\", \"GULF.BK\", \"HMPRO.BK\", \"INTUCH.BK\",\n",
    "    \"IRPC.BK\", \"IVL.BK\", \"KBANK.BK\", \"KCE.BK\", \"KTB.BK\", \"KTC.BK\",\n",
    "    \"LH.BK\", \"MINT.BK\", \"MTC.BK\", \"OR.BK\", \"OSP.BK\", \"PTT.BK\",\n",
    "    \"PTTEP.BK\", \"PTTGC.BK\", \"RATCH.BK\", \"SAWAD.BK\", \"SCB.BK\", \"SCC.BK\",\n",
    "    \"SCGP.BK\", \"STA.BK\", \"STGT.BK\", \"TISCO.BK\", \"TOP.BK\", \"TTB.BK\",\n",
    "    \"TU.BK\", \"TRUE.BK\"\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(f\"{'‚öôÔ∏è  CONFIGURATION':^90}\")\n",
    "print(\"=\"*90)\n",
    "print(f\"\\nüìä Portfolio Size (N): {N_STOCKS}\")\n",
    "print(f\"üí∞ Investment Fund: {FUND:,.0f} THB\")\n",
    "print(f\"üé≤ Weight Samples: {NUM_WEIGHT_SAMPLES:,}\")\n",
    "print(f\"üìÖ Date Range: {START_DATE} to {END_DATE}\")\n",
    "print(f\"üè¢ Number of Stocks: {len(STOCK_LIST)}\")\n",
    "print(f\"üì¶ Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"üéØ Return Targets: {len(RETURN_TARGETS)} levels\")\n",
    "print(\"\\n\" + \"=\"*90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7349d573",
   "metadata": {},
   "source": [
    "## üì• Step 7: Download Stock Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ae1416",
   "metadata": {},
   "source": [
    "## üé≤ Step 8: Generate Weight Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711bff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nüé≤ Generating {NUM_WEIGHT_SAMPLES:,} random weight combinations...\")\n",
    "print(f\"   (Weights sum to 1.0 using Dirichlet distribution)\")\n",
    "\n",
    "start_weights = time.time()\n",
    "dist = tfp.distributions.Dirichlet(np.ones(N_STOCKS))\n",
    "Wi = dist.sample(NUM_WEIGHT_SAMPLES)\n",
    "weights_time = time.time() - start_weights\n",
    "\n",
    "print(f\"‚úÖ Weight generation complete in {weights_time:.2f} seconds\")\n",
    "print(f\"üìä Weight tensor shape: {Wi.shape}\")\n",
    "print(f\"\\nüìã Sample weights (first 5):\")\n",
    "print(Wi[:5].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372f173a",
   "metadata": {},
   "source": [
    "## üîÑ Step 9: Generate Stock Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4e51f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nüîÑ Generating all possible stock combinations (N={N_STOCKS})...\")\n",
    "print(f\"   Using {len(STOCK_LIST)} available stocks\")\n",
    "\n",
    "start_combinations = time.time()\n",
    "companies = np.array(list(itertools.combinations(STOCK_LIST, N_STOCKS)))\n",
    "combinations_time = time.time() - start_combinations\n",
    "\n",
    "print(f\"\\n‚úÖ Combination generation complete in {combinations_time:.2f} seconds\")\n",
    "print(f\"üìä Total combinations: {len(companies):,}\")\n",
    "print(f\"üí° Formula: C({len(STOCK_LIST)},{N_STOCKS}) = {len(companies):,}\")\n",
    "print(f\"\\nüìã Sample combinations (first 5):\")\n",
    "for i, combo in enumerate(companies[:5]):\n",
    "    print(f\"   {i+1}. {', '.join(combo)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25107f4f",
   "metadata": {},
   "source": [
    "## üöÄ Step 10: Run Ultra-Fast Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb65399c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nüì• Downloading stock data for {len(STOCK_LIST)} stocks...\")\n",
    "print(f\"üìÖ Period: {START_DATE} to {END_DATE}\")\n",
    "print(f\"‚ö†Ô∏è  Note: Some stocks may fail to download due to API limitations\\n\")\n",
    "\n",
    "start_download = time.time()\n",
    "\n",
    "# Download with error handling - try individual downloads if batch fails\n",
    "try:\n",
    "    # Try batch download first (faster)\n",
    "    df_prices = yf.download(STOCK_LIST, start=START_DATE, end=END_DATE, progress=True, \n",
    "                           group_by='column', threads=True, ignore_tz=True)\n",
    "    download_time = time.time() - start_download\n",
    "    \n",
    "    # Check if we got data\n",
    "    if df_prices.empty:\n",
    "        raise Exception(\"No data downloaded\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Batch download complete in {download_time:.2f} seconds\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ö†Ô∏è  Batch download failed: {e}\")\n",
    "    print(f\"üîÑ Trying individual stock downloads...\\n\")\n",
    "    \n",
    "    # Download stocks individually\n",
    "    successful_stocks = []\n",
    "    failed_stocks = []\n",
    "    individual_data = {}\n",
    "    \n",
    "    for stock in tqdm(STOCK_LIST, desc=\"Downloading\", ncols=80):\n",
    "        try:\n",
    "            stock_data = yf.download(stock, start=START_DATE, end=END_DATE, \n",
    "                                    progress=False, ignore_tz=True)\n",
    "            if not stock_data.empty and 'Close' in stock_data.columns:\n",
    "                individual_data[stock] = stock_data['Close']\n",
    "                successful_stocks.append(stock)\n",
    "            else:\n",
    "                failed_stocks.append(stock)\n",
    "        except Exception as ex:\n",
    "            failed_stocks.append(stock)\n",
    "    \n",
    "    # Combine individual downloads\n",
    "    if individual_data:\n",
    "        df_prices = pd.DataFrame(individual_data)\n",
    "        # Add MultiIndex for compatibility\n",
    "        df_prices.columns = pd.MultiIndex.from_product([['Close'], df_prices.columns])\n",
    "    else:\n",
    "        raise Exception(\"Failed to download any stock data\")\n",
    "    \n",
    "    download_time = time.time() - start_download\n",
    "    \n",
    "    print(f\"\\n‚úÖ Individual download complete in {download_time:.2f} seconds\")\n",
    "    print(f\"‚úÖ Successfully downloaded: {len(successful_stocks)} stocks\")\n",
    "    if failed_stocks:\n",
    "        print(f\"‚ö†Ô∏è  Failed to download: {len(failed_stocks)} stocks\")\n",
    "        print(f\"   Failed stocks: {', '.join(failed_stocks[:10])}\")\n",
    "        if len(failed_stocks) > 10:\n",
    "            print(f\"   ... and {len(failed_stocks) - 10} more\")\n",
    "        \n",
    "        # Update STOCK_LIST to only include successful stocks\n",
    "        STOCK_LIST = successful_stocks\n",
    "        print(f\"\\nüìä Continuing with {len(STOCK_LIST)} available stocks\")\n",
    "\n",
    "# Display summary\n",
    "print(f\"\\nüìä Data shape: {df_prices.shape}\")\n",
    "print(f\"üìà Trading days: {len(df_prices)}\")\n",
    "\n",
    "# Check for missing data\n",
    "if 'Close' in df_prices.columns.names:\n",
    "    close_prices = df_prices['Close']\n",
    "    missing_pct = (close_prices.isnull().sum() / len(close_prices) * 100)\n",
    "    stocks_with_missing = missing_pct[missing_pct > 0]\n",
    "    if len(stocks_with_missing) > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è  Stocks with missing data:\")\n",
    "        for stock, pct in stocks_with_missing.items():\n",
    "            print(f\"   {stock}: {pct:.1f}% missing\")\n",
    "        print(f\"\\nüîß Will handle missing data during optimization\")\n",
    "\n",
    "# Display sample data\n",
    "print(f\"\\nüìã Sample Data (first 3 rows, first 5 stocks):\")\n",
    "if 'Close' in df_prices.columns.names:\n",
    "    print(df_prices['Close'].iloc[:3, :min(5, df_prices['Close'].shape[1])])\n",
    "else:\n",
    "    print(df_prices.iloc[:3, :min(5, df_prices.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008cbdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and validate the downloaded data\n",
    "print(f\"\\nüßπ Cleaning and validating data...\")\n",
    "\n",
    "# Get close prices\n",
    "if 'Close' in df_prices.columns.names:\n",
    "    close_prices = df_prices['Close'].copy()\n",
    "else:\n",
    "    close_prices = df_prices.copy()\n",
    "\n",
    "# Remove stocks with too much missing data (>20%)\n",
    "initial_stock_count = len(close_prices.columns)\n",
    "missing_threshold = 0.20\n",
    "stocks_to_remove = []\n",
    "\n",
    "for stock in close_prices.columns:\n",
    "    missing_pct = close_prices[stock].isnull().sum() / len(close_prices)\n",
    "    if missing_pct > missing_threshold:\n",
    "        stocks_to_remove.append(stock)\n",
    "\n",
    "if stocks_to_remove:\n",
    "    print(f\"\\n‚ö†Ô∏è  Removing {len(stocks_to_remove)} stocks with >{missing_threshold*100}% missing data:\")\n",
    "    for stock in stocks_to_remove:\n",
    "        print(f\"   - {stock}\")\n",
    "    close_prices = close_prices.drop(columns=stocks_to_remove)\n",
    "    STOCK_LIST = [s for s in STOCK_LIST if s not in stocks_to_remove]\n",
    "\n",
    "# Forward fill remaining missing data\n",
    "close_prices = close_prices.fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "# Remove stocks with any remaining NaN or zero values\n",
    "stocks_to_remove_final = []\n",
    "for stock in close_prices.columns:\n",
    "    if close_prices[stock].isnull().any() or (close_prices[stock] <= 0).any():\n",
    "        stocks_to_remove_final.append(stock)\n",
    "\n",
    "if stocks_to_remove_final:\n",
    "    print(f\"\\n‚ö†Ô∏è  Removing {len(stocks_to_remove_final)} stocks with invalid data:\")\n",
    "    for stock in stocks_to_remove_final:\n",
    "        print(f\"   - {stock}\")\n",
    "    close_prices = close_prices.drop(columns=stocks_to_remove_final)\n",
    "    STOCK_LIST = [s for s in STOCK_LIST if s not in stocks_to_remove_final]\n",
    "\n",
    "# Update the main dataframe\n",
    "if 'Close' in df_prices.columns.names:\n",
    "    df_prices = df_prices[[('Close', stock) for stock in close_prices.columns]]\n",
    "    df_prices.columns = pd.MultiIndex.from_product([['Close'], close_prices.columns])\n",
    "else:\n",
    "    df_prices = close_prices\n",
    "\n",
    "print(f\"\\n‚úÖ Data cleaning complete!\")\n",
    "print(f\"üìä Stocks after cleaning: {len(STOCK_LIST)} (removed {initial_stock_count - len(STOCK_LIST)})\")\n",
    "print(f\"üìà Trading days: {len(df_prices)}\")\n",
    "print(f\"‚úì No missing values: {not df_prices.isnull().any().any()}\")\n",
    "print(f\"‚úì All prices > 0: {(df_prices > 0).all().all()}\")\n",
    "\n",
    "# Display final stock list\n",
    "print(f\"\\nüìã Final stock list ({len(STOCK_LIST)} stocks):\")\n",
    "print(f\"   {', '.join(STOCK_LIST)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48828eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize optimizer\n",
    "optimizer = UltraFastPortfolioOptimizer(\n",
    "    df=df_prices,\n",
    "    companies=companies,\n",
    "    Wi=Wi,\n",
    "    fund=FUND,\n",
    "    n_stocks=N_STOCKS,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Run optimization\n",
    "best_portfolios, all_results = optimizer.optimize_multiple_returns(\n",
    "    return_targets=RETURN_TARGETS,\n",
    "    max_combinations=MAX_COMBINATIONS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f32d9cf",
   "metadata": {},
   "source": [
    "## üìä Step 11: Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f90070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display beautiful results\n",
    "display_results(best_portfolios, RETURN_TARGETS, df_prices, FUND, N_STOCKS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3a6d3e",
   "metadata": {},
   "source": [
    "## üíæ Step 12: Save Results to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18278931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file\n",
    "output_filename = f\"portfolio_optimization_N{N_STOCKS}_results.txt\"\n",
    "save_results_to_file(best_portfolios, RETURN_TARGETS, N_STOCKS, output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82c66fa",
   "metadata": {},
   "source": [
    "## üìà Step 13: Detailed Analysis of Best Portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de0e05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary DataFrame\n",
    "summary_data = []\n",
    "for target_idx, (min_ret, max_ret) in enumerate(RETURN_TARGETS):\n",
    "    portfolio = best_portfolios[target_idx]\n",
    "    if portfolio['volatility'] is not None:\n",
    "        summary_data.append({\n",
    "            'Target Return (%)': (min_ret + max_ret) / 2,\n",
    "            'Actual Return (%)': portfolio['avg_return'],\n",
    "            'Volatility': portfolio['volatility'],\n",
    "            'Variance': portfolio['variance'],\n",
    "            'Stocks': ', '.join(portfolio['companies']),\n",
    "            'Status': '‚úÖ Found'\n",
    "        })\n",
    "    else:\n",
    "        summary_data.append({\n",
    "            'Target Return (%)': (min_ret + max_ret) / 2,\n",
    "            'Actual Return (%)': None,\n",
    "            'Volatility': None,\n",
    "            'Variance': None,\n",
    "            'Stocks': None,\n",
    "            'Status': '‚ùå Not Found'\n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(f\"{'üìä OPTIMIZATION SUMMARY':^90}\")\n",
    "print(\"=\"*90 + \"\\n\")\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773700e5",
   "metadata": {},
   "source": [
    "## üîç Step 14: Analyze Single Portfolio in Detail (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467262b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze a specific return target in detail\n",
    "TARGET_TO_ANALYZE = 0  # Index: 0=1%, 1=2%, 2=3%, 3=4%, 4=5%\n",
    "\n",
    "portfolio = best_portfolios[TARGET_TO_ANALYZE]\n",
    "\n",
    "if portfolio['volatility'] is not None:\n",
    "    print(f\"\\n{'='*90}\")\n",
    "    print(f\"{'üîç DETAILED PORTFOLIO ANALYSIS':^90}\")\n",
    "    print(f\"{'Target Return: ' + str(portfolio['target_return']) + '%':^90}\")\n",
    "    print(f\"{'='*90}\\n\")\n",
    "    \n",
    "    companies = portfolio['companies']\n",
    "    weights = portfolio['weights']\n",
    "    \n",
    "    # Get price data for these stocks\n",
    "    if 'Close' in df_prices.columns.names:\n",
    "        stock_prices = df_prices['Close'][list(companies)]\n",
    "    else:\n",
    "        stock_prices = df_prices[list(companies)]\n",
    "    \n",
    "    print(f\"\\nüìà Historical Performance:\")\n",
    "    print(f\"   Start Price: {stock_prices.iloc[0].to_dict()}\")\n",
    "    print(f\"   End Price:   {stock_prices.iloc[-1].to_dict()}\")\n",
    "    \n",
    "    # Calculate individual stock returns\n",
    "    print(f\"\\nüìä Individual Stock Returns:\")\n",
    "    for stock in companies:\n",
    "        start_price = stock_prices[stock].iloc[0]\n",
    "        end_price = stock_prices[stock].iloc[-1]\n",
    "        stock_return = (end_price - start_price) / start_price * 100\n",
    "        print(f\"   {stock:<15} Return: {stock_return:>8.2f}%\")\n",
    "    \n",
    "    print(f\"\\nüéØ Optimal Weights:\")\n",
    "    for stock, weight in zip(companies, weights):\n",
    "        print(f\"   {stock:<15} Weight: {weight:>8.4f} ({weight*100:>6.2f}%)\")\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*90)\n",
    "else:\n",
    "    print(f\"\\n‚ùå No portfolio found for target return {portfolio['target_return']}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f70207c",
   "metadata": {},
   "source": [
    "## üìä Step 15: Export Results to Excel (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea6efc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to Excel with multiple sheets\n",
    "excel_filename = f\"portfolio_optimization_N{N_STOCKS}_results.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(excel_filename, engine='xlsxwriter') as writer:\n",
    "    # Summary sheet\n",
    "    summary_df.to_excel(writer, sheet_name='Summary', index=False)\n",
    "    \n",
    "    # Detailed results for each target\n",
    "    for target_idx, (min_ret, max_ret) in enumerate(RETURN_TARGETS):\n",
    "        portfolio = best_portfolios[target_idx]\n",
    "        target_return = (min_ret + max_ret) / 2\n",
    "        \n",
    "        if portfolio['volatility'] is not None:\n",
    "            # Create detailed DataFrame\n",
    "            detail_data = []\n",
    "            companies = portfolio['companies']\n",
    "            weights = portfolio['weights']\n",
    "            \n",
    "            # Get latest prices\n",
    "            latest_prices = {}\n",
    "            for stock in companies:\n",
    "                try:\n",
    "                    if 'Close' in df_prices.columns.names:\n",
    "                        latest_prices[stock] = df_prices['Close'][stock].iloc[-1]\n",
    "                    else:\n",
    "                        latest_prices[stock] = df_prices[stock].iloc[-1]\n",
    "                except:\n",
    "                    latest_prices[stock] = 0.0\n",
    "            \n",
    "            allocation, total_invested, remaining = calculate_allocation(\n",
    "                weights, FUND, latest_prices\n",
    "            )\n",
    "            \n",
    "            for stock in companies:\n",
    "                info = allocation[stock]\n",
    "                detail_data.append({\n",
    "                    'Stock': stock,\n",
    "                    'Weight': info['weight'],\n",
    "                    'Weight (%)': info['weight'] * 100,\n",
    "                    'Shares': info['shares'],\n",
    "                    'Price': info['price'],\n",
    "                    'Invested': info['invested']\n",
    "                })\n",
    "            \n",
    "            detail_df = pd.DataFrame(detail_data)\n",
    "            sheet_name = f'{target_return:.0f}% Return'\n",
    "            detail_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(f\"\\nüíæ Excel file saved: {excel_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a82e35a",
   "metadata": {},
   "source": [
    "## üéØ Step 16: Quick Comparison - Different Portfolio Sizes (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc48648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell allows you to quickly test different portfolio sizes\n",
    "# Uncomment and run to compare N=2, N=3, N=5\n",
    "\n",
    "'''\n",
    "results_comparison = {}\n",
    "\n",
    "for n in [2, 3, 5]:\n",
    "    print(f\"\\n{'='*90}\")\n",
    "    print(f\"Testing N={n}\")\n",
    "    print(f\"{'='*90}\")\n",
    "    \n",
    "    # Generate weights\n",
    "    dist = tfp.distributions.Dirichlet(np.ones(n))\n",
    "    Wi_test = dist.sample(50000)  # Reduced for speed\n",
    "    \n",
    "    # Generate combinations\n",
    "    companies_test = np.array(list(itertools.combinations(STOCK_LIST, n)))\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    optimizer_test = UltraFastPortfolioOptimizer(\n",
    "        df=df_prices,\n",
    "        companies=companies_test,\n",
    "        Wi=Wi_test,\n",
    "        fund=FUND,\n",
    "        n_stocks=n,\n",
    "        batch_size=50\n",
    "    )\n",
    "    \n",
    "    # Optimize (limit to 500 combinations for quick test)\n",
    "    best_test, _ = optimizer_test.optimize_multiple_returns(\n",
    "        return_targets=RETURN_TARGETS[:3],  # Only test 1%, 2%, 3%\n",
    "        max_combinations=500\n",
    "    )\n",
    "    \n",
    "    results_comparison[n] = best_test\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"Comparison Complete!\")\n",
    "print(\"=\"*90)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b121071",
   "metadata": {},
   "source": [
    "## üìù Notes and Tips\n",
    "\n",
    "### Performance Optimization Tips:\n",
    "1. **GPU Usage**: Ensure GPU is available for maximum speed (10-50x faster)\n",
    "2. **Batch Size**: Increase for faster processing (if memory allows)\n",
    "3. **Weight Samples**: More samples = better results but slower\n",
    "4. **Portfolio Size**: N=2 is fastest, N=5 is slower but more diversified\n",
    "\n",
    "### Memory Management:\n",
    "- Reduce `NUM_WEIGHT_SAMPLES` if running out of memory\n",
    "- Reduce `BATCH_SIZE` if GPU memory errors occur\n",
    "- Use `MAX_COMBINATIONS` for testing before full run\n",
    "\n",
    "### Expected Performance:\n",
    "- **N=2**: ~1,225 combinations, ~30-60 seconds\n",
    "- **N=3**: ~19,600 combinations, ~5-10 minutes\n",
    "- **N=5**: ~2.1M combinations, ~1-3 hours (GPU), ~10-30 hours (CPU)\n",
    "\n",
    "### Customization:\n",
    "- Modify `RETURN_TARGETS` for different return levels\n",
    "- Change `STOCK_LIST` to use different stocks\n",
    "- Adjust date range for different time periods\n",
    "- Modify volatility calculation method if needed"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
